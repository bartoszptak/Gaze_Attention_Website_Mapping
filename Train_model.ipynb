{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wstęp do trenowanej sieci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Wczytanie bibliotek do przetwarzania danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "7736EJluandP",
    "outputId": "bd1dd0cb-d36b-4e67-e647-0168f858072a"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 120, 3)\n"
     ]
    }
   ],
   "source": [
    "path = glob.glob(os.path.join('data', 'eyes', '*.npy'))\n",
    "data_set = []\n",
    "\n",
    "for a in path:\n",
    "    data_set += np.load(a).tolist()\n",
    "\n",
    "data_set = np.array(data_set)\n",
    "print(data_set[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Ustawienie parametrów skalowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleX = 1.2\n",
    "scaleY = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Rozbicie danych na wejściowe i wyjściowe, przeskalowanie, zwolnienie niepotrzebnej pamięci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "WCUv4Dzqap1Y",
    "outputId": "3dca1139-743e-49ed-fca7-f3f80135478c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2272 (2272, 90, 144, 1)\n",
      "2272 (2272, 6)\n"
     ]
    }
   ],
   "source": [
    "X_ = data_set[:, 0:1]\n",
    "Y_ = data_set[:, 1:7]\n",
    "\n",
    "Xx = []\n",
    "Y = []\n",
    "\n",
    "for x in X_:\n",
    "    local = cv2.resize(x[0], None, fx=scaleX, fy=scaleY)\n",
    "    local = cv2.cvtColor(local, cv2.COLOR_BGR2GRAY)\n",
    "    local = cv2.equalizeHist(local)\n",
    "    Xx.append(local * 1. / 255)\n",
    "\n",
    "for y in Y_:\n",
    "    y[0] *= scaleX\n",
    "    y[1] *= scaleY\n",
    "    y[2] *= scaleX\n",
    "    y[3] *= scaleY\n",
    "    y[4] *= scaleX\n",
    "    y[5] *= scaleY\n",
    "Y = np.array(Y_)\n",
    "\n",
    "Xx = np.array(Xx)\n",
    "X = Xx[..., np.newaxis]\n",
    "\n",
    "del data_set\n",
    "del X_\n",
    "del Y_\n",
    "del Xx\n",
    "\n",
    "print(len(X), X.shape)\n",
    "print(len(Y), Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Wczytywanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MWxfN78Ncwl0",
    "outputId": "781317ba-33d5-4a42-f2f0-f81d6cbf965f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from Model import Model\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 144, 64)       640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 45, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 45, 72, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 22, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 101376)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              101377000 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 6006      \n",
      "=================================================================\n",
      "Total params: 101,457,502\n",
      "Trainable params: 101,457,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2044 samples, validate on 228 samples\n",
      "Epoch 1/100\n",
      "2044/2044 [==============================] - 17s 8ms/step - loss: 347.7927 - val_loss: 53.1954\n",
      "Epoch 2/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 61.3972 - val_loss: 49.0898\n",
      "Epoch 3/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 49.7828 - val_loss: 46.1192\n",
      "Epoch 4/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 41.9110 - val_loss: 39.7594\n",
      "Epoch 5/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 37.8762 - val_loss: 34.4477\n",
      "Epoch 6/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 34.2056 - val_loss: 37.7155\n",
      "Epoch 7/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 33.3531 - val_loss: 39.3076\n",
      "Epoch 8/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 32.4815 - val_loss: 33.8034\n",
      "Epoch 9/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 29.0577 - val_loss: 33.7997\n",
      "Epoch 10/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 30.0564 - val_loss: 36.9571\n",
      "Epoch 11/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 28.1713 - val_loss: 38.2627\n",
      "Epoch 12/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 28.5937 - val_loss: 33.4135\n",
      "Epoch 13/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 25.3781 - val_loss: 32.6892\n",
      "Epoch 14/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 23.4327 - val_loss: 33.7464\n",
      "Epoch 15/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 24.1882 - val_loss: 34.4358\n",
      "Epoch 16/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 27.9636 - val_loss: 33.6265\n",
      "Epoch 17/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 25.1505 - val_loss: 33.1893\n",
      "Epoch 18/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 22.5937 - val_loss: 33.4786\n",
      "Epoch 19/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 26.0223 - val_loss: 38.8035\n",
      "Epoch 20/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 23.2741 - val_loss: 42.7005\n",
      "Epoch 21/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 23.6969 - val_loss: 35.4843\n",
      "Epoch 22/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 21.9505 - val_loss: 34.0511\n",
      "Epoch 23/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 20.4527 - val_loss: 35.1398\n",
      "Epoch 24/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 19.7053 - val_loss: 34.0914\n",
      "Epoch 25/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 19.5875 - val_loss: 32.5549\n",
      "Epoch 26/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 19.3294 - val_loss: 33.4676\n",
      "Epoch 27/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 18.9218 - val_loss: 32.9187\n",
      "Epoch 28/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 19.4587 - val_loss: 33.2505\n",
      "Epoch 29/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 18.6614 - val_loss: 31.6630\n",
      "Epoch 30/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 19.6848 - val_loss: 31.4851\n",
      "Epoch 31/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 20.0293 - val_loss: 32.1896\n",
      "Epoch 32/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 19.1508 - val_loss: 32.7915\n",
      "Epoch 33/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 20.1810 - val_loss: 33.3304\n",
      "Epoch 34/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 19.6602 - val_loss: 33.5899\n",
      "Epoch 35/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 20.6268 - val_loss: 31.2612\n",
      "Epoch 36/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 17.4126 - val_loss: 37.1825\n",
      "Epoch 37/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 16.9502 - val_loss: 31.9913\n",
      "Epoch 38/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 17.3192 - val_loss: 32.8462\n",
      "Epoch 39/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 18.2172 - val_loss: 32.2520\n",
      "Epoch 40/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 21.9954 - val_loss: 33.9320\n",
      "Epoch 41/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 17.0785 - val_loss: 31.0633\n",
      "Epoch 42/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 17.1664 - val_loss: 44.3152\n",
      "Epoch 43/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 17.0927 - val_loss: 30.1694\n",
      "Epoch 44/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 16.0743 - val_loss: 31.5829\n",
      "Epoch 45/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 16.2167 - val_loss: 35.3791\n",
      "Epoch 46/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 17.1082 - val_loss: 34.7695\n",
      "Epoch 47/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 16.4439 - val_loss: 30.9981\n",
      "Epoch 48/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 15.4573 - val_loss: 31.6033\n",
      "Epoch 49/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 16.0623 - val_loss: 33.3080\n",
      "Epoch 50/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 17.1853 - val_loss: 36.8521\n",
      "Epoch 51/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 15.5482 - val_loss: 36.6203\n",
      "Epoch 52/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 15.4920 - val_loss: 33.7822\n",
      "Epoch 53/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 15.1896 - val_loss: 31.3197\n",
      "Epoch 54/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 14.7949 - val_loss: 31.4558\n",
      "Epoch 55/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 15.1578 - val_loss: 31.2878\n",
      "Epoch 56/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 15.7149 - val_loss: 31.3350\n",
      "Epoch 57/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 15.9229 - val_loss: 32.9004\n",
      "Epoch 58/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 14.8910 - val_loss: 34.1158\n",
      "Epoch 59/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 14.3434 - val_loss: 34.1665\n",
      "Epoch 60/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 15.0094 - val_loss: 31.9209\n",
      "Epoch 61/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 15.5781 - val_loss: 32.3340\n",
      "Epoch 62/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 14.6476 - val_loss: 32.6248\n",
      "Epoch 63/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 13.8278 - val_loss: 30.3462\n",
      "Epoch 64/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 14.8925 - val_loss: 31.5216\n",
      "Epoch 65/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 15.5183 - val_loss: 31.9129\n",
      "Epoch 66/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 16.2774 - val_loss: 31.2726\n",
      "Epoch 67/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 15.1435 - val_loss: 31.2983\n",
      "Epoch 68/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 13.5579 - val_loss: 31.3829\n",
      "Epoch 69/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 13.7438 - val_loss: 32.4445\n",
      "Epoch 70/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 13.5905 - val_loss: 31.4066\n",
      "Epoch 71/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 13.1147 - val_loss: 30.8834\n",
      "Epoch 72/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 13.4457 - val_loss: 31.3804\n",
      "Epoch 73/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 13.5464 - val_loss: 32.8133\n",
      "Epoch 74/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 14.3637 - val_loss: 30.8110\n",
      "Epoch 75/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 13.5773 - val_loss: 32.8408\n",
      "Epoch 76/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 13.5781 - val_loss: 32.6695\n",
      "Epoch 77/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 13.9343 - val_loss: 31.9955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 14.7314 - val_loss: 31.7235\n",
      "Epoch 79/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 13.7352 - val_loss: 31.1850\n",
      "Epoch 80/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 14.9778 - val_loss: 31.0118\n",
      "Epoch 81/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 13.6196 - val_loss: 29.7385\n",
      "Epoch 82/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 12.4399 - val_loss: 35.8095\n",
      "Epoch 83/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 12.6147 - val_loss: 31.0551\n",
      "Epoch 84/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 12.8468 - val_loss: 34.5768\n",
      "Epoch 85/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 12.0943 - val_loss: 32.5260\n",
      "Epoch 86/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 14.5503 - val_loss: 31.0250\n",
      "Epoch 87/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 12.9114 - val_loss: 28.7501\n",
      "Epoch 88/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 13.5495 - val_loss: 31.5041\n",
      "Epoch 89/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 13.0474 - val_loss: 32.1259\n",
      "Epoch 90/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 12.1728 - val_loss: 32.5373\n",
      "Epoch 91/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 12.2719 - val_loss: 32.3409\n",
      "Epoch 92/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 11.9364 - val_loss: 32.0422\n",
      "Epoch 93/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 12.6657 - val_loss: 32.1750\n",
      "Epoch 94/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 12.4096 - val_loss: 30.7102\n",
      "Epoch 95/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 11.6410 - val_loss: 32.8170\n",
      "Epoch 96/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 11.6494 - val_loss: 31.9888\n",
      "Epoch 97/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 12.0992 - val_loss: 30.6701\n",
      "Epoch 98/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 12.2109 - val_loss: 30.7956\n",
      "Epoch 99/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 13.3344 - val_loss: 33.4270\n",
      "Epoch 100/100\n",
      "2044/2044 [==============================] - 9s 4ms/step - loss: 11.8503 - val_loss: 30.6957\n"
     ]
    }
   ],
   "source": [
    "model.train(X, Y, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [53.19543965657552,\n",
       "  49.089798174406354,\n",
       "  46.119226689924275,\n",
       "  39.75943006548965,\n",
       "  34.44765479104561,\n",
       "  37.71549127812971,\n",
       "  39.30763157627039,\n",
       "  33.8033628965679,\n",
       "  33.799720563386614,\n",
       "  36.95706313953065,\n",
       "  38.26274928712008,\n",
       "  33.41347436737596,\n",
       "  32.68917097125137,\n",
       "  33.746372289824905,\n",
       "  34.43575828953793,\n",
       "  33.62654709397701,\n",
       "  33.189257638496265,\n",
       "  33.47861591138338,\n",
       "  38.80353345369038,\n",
       "  42.70050256294117,\n",
       "  35.48431396484375,\n",
       "  34.05106728537041,\n",
       "  35.139802631578945,\n",
       "  34.09140248884235,\n",
       "  32.554899985330145,\n",
       "  33.46758788928651,\n",
       "  32.91873543722588,\n",
       "  33.25050233539782,\n",
       "  31.663019146835595,\n",
       "  31.485086006030702,\n",
       "  32.18962585716917,\n",
       "  32.79152967218767,\n",
       "  33.33039708723102,\n",
       "  33.58988865634851,\n",
       "  31.261213938395183,\n",
       "  37.18254122817726,\n",
       "  31.991345656545537,\n",
       "  32.846205393473305,\n",
       "  32.25199033502947,\n",
       "  33.93197845994381,\n",
       "  31.06334672894394,\n",
       "  44.31519157008121,\n",
       "  30.169425763581927,\n",
       "  31.582904547975776,\n",
       "  35.379064058002676,\n",
       "  34.769510302627296,\n",
       "  30.99807856375711,\n",
       "  31.603278979920503,\n",
       "  33.30799618101957,\n",
       "  36.85207065783049,\n",
       "  36.620256658185994,\n",
       "  33.78224336055287,\n",
       "  31.319683275724714,\n",
       "  31.45583176194576,\n",
       "  31.287759680497018,\n",
       "  31.334989313493693,\n",
       "  32.90041264316492,\n",
       "  34.115812268173485,\n",
       "  34.16653777005379,\n",
       "  31.92090298836691,\n",
       "  32.33397152549342,\n",
       "  32.62482084307754,\n",
       "  30.346213825962,\n",
       "  31.52164994624623,\n",
       "  31.91287586145234,\n",
       "  31.272623363294098,\n",
       "  31.298260203579016,\n",
       "  31.382854863217002,\n",
       "  32.44448096292061,\n",
       "  31.406557852761786,\n",
       "  30.88338878698516,\n",
       "  31.38036955448619,\n",
       "  32.813302157218,\n",
       "  30.811045596474095,\n",
       "  32.84076235587137,\n",
       "  32.66954160991468,\n",
       "  31.995465194969846,\n",
       "  31.723513218394498,\n",
       "  31.185001975611637,\n",
       "  31.011840954161528,\n",
       "  29.738459202281216,\n",
       "  35.809548562033136,\n",
       "  31.055109793679755,\n",
       "  34.57681153949938,\n",
       "  32.525964435778164,\n",
       "  31.0249661228113,\n",
       "  28.750144155401934,\n",
       "  31.504089623166802,\n",
       "  32.1259362070184,\n",
       "  32.53726805302135,\n",
       "  32.34092913175884,\n",
       "  32.04221999854372,\n",
       "  32.17500880726597,\n",
       "  30.710168537340667,\n",
       "  32.81700783445124,\n",
       "  31.988840738932293,\n",
       "  30.670058467931916,\n",
       "  30.79563421952097,\n",
       "  33.42703615155136,\n",
       "  30.695740013791802],\n",
       " 'loss': [347.7926705317488,\n",
       "  61.39724341763909,\n",
       "  49.7827670476208,\n",
       "  41.91102573969593,\n",
       "  37.876231061035874,\n",
       "  34.205642789777244,\n",
       "  33.353125219475736,\n",
       "  32.481481809672076,\n",
       "  29.057720815132274,\n",
       "  30.056436859698213,\n",
       "  28.17129331838828,\n",
       "  28.59366035834684,\n",
       "  25.378123162077365,\n",
       "  23.432741945270458,\n",
       "  24.1882165584079,\n",
       "  27.96355733106281,\n",
       "  25.15054808017559,\n",
       "  22.593729903786617,\n",
       "  26.022324033912614,\n",
       "  23.274133600134206,\n",
       "  23.696931667290556,\n",
       "  21.95047271601608,\n",
       "  20.452705722965607,\n",
       "  19.70528033008314,\n",
       "  19.587485987146305,\n",
       "  19.329404752548427,\n",
       "  18.921826603361307,\n",
       "  19.458722232139273,\n",
       "  18.661437230567408,\n",
       "  19.684816558300398,\n",
       "  20.029310121928177,\n",
       "  19.150761524058602,\n",
       "  20.180996213640487,\n",
       "  19.66015947868213,\n",
       "  20.626770041926733,\n",
       "  17.412582020470307,\n",
       "  16.950249293079114,\n",
       "  17.319214042618782,\n",
       "  18.21717750489595,\n",
       "  21.995395096780737,\n",
       "  17.078507328220077,\n",
       "  17.166428952301086,\n",
       "  17.09272168153886,\n",
       "  16.074262977346283,\n",
       "  16.21670824114357,\n",
       "  17.108239653525754,\n",
       "  16.443904718074315,\n",
       "  15.457284178985775,\n",
       "  16.062328379681432,\n",
       "  17.18525398314116,\n",
       "  15.548167355606468,\n",
       "  15.491980690778819,\n",
       "  15.189632540812932,\n",
       "  14.794889466869854,\n",
       "  15.157812863180082,\n",
       "  15.714871688365003,\n",
       "  15.922915897257408,\n",
       "  14.890959256315885,\n",
       "  14.343362084106923,\n",
       "  15.009378257796255,\n",
       "  15.578054644590255,\n",
       "  14.64762948217224,\n",
       "  13.827812260144377,\n",
       "  14.892499757606222,\n",
       "  15.51827297471974,\n",
       "  16.277408226595465,\n",
       "  15.143501940538739,\n",
       "  13.557902539546243,\n",
       "  13.74383575715664,\n",
       "  13.590513576500102,\n",
       "  13.114683811911865,\n",
       "  13.445663050896034,\n",
       "  13.546407191954014,\n",
       "  14.363676562001327,\n",
       "  13.577252442122905,\n",
       "  13.578067113275397,\n",
       "  13.934292304305881,\n",
       "  14.731367656162806,\n",
       "  13.735244375852222,\n",
       "  14.977756843641545,\n",
       "  13.619598319619136,\n",
       "  12.43991295278889,\n",
       "  12.614674142662093,\n",
       "  12.846772615690288,\n",
       "  12.094304247145084,\n",
       "  14.550348289325512,\n",
       "  12.911426258647046,\n",
       "  13.549534056751229,\n",
       "  13.047360448221404,\n",
       "  12.172819992334176,\n",
       "  12.271926642863951,\n",
       "  11.936375554527089,\n",
       "  12.665654794577284,\n",
       "  12.409558531356184,\n",
       "  11.640972447255352,\n",
       "  11.649368090172336,\n",
       "  12.09919654226583,\n",
       "  12.210934295579646,\n",
       "  13.334449930433658,\n",
       "  11.850271361214775]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Train.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
